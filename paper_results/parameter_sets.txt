name = 'results_normal60'
num_episodes = 150
_learn_biased_model = False
_include_cart_velocity = True
_observation_noise_std = None
_time_compression = 6
_planning_horizon = 10
n_policy_samples=700,
policy_iterations=2,
n_policy_candidates=70,
action_window=2
# > Training time ~25min

name = 'results_normal90'
num_episodes = 150
_learn_biased_model = False
_include_cart_velocity = True
_observation_noise_std = None
_time_compression = 6
_planning_horizon = 15
n_policy_samples=1500,
policy_iterations=2,
n_policy_candidates=70,
action_window=2
# > Training time ~30min

name = 'results_random'
num_episodes = 150
_learn_biased_model = False
_include_cart_velocity = True
_observation_noise_std = None # 0.08
_time_compression = 6
_planning_horizon = 3
policy_dim=1,
n_policy_samples=1,
policy_iterations=1,
n_policy_candidates=1,
action_window=2
# > Training time ~7min

name = 'results_bellman36'
_learn_biased_model = True
biased_model = BiasedModelBellman(observation_dim=2 if _include_cart_velocity else 1, learning_rate=0.1, iterate_train=15, discount_factor=0.995)
_include_cart_velocity = True
_observation_noise_std = None
_time_compression = 6
_planning_horizon = 6
n_policy_samples=700,
policy_iterations=2,
n_policy_candidates=70,
action_window=2
# > training time ~5min


name = 'results_bellman36_noise'
_learn_biased_model = True
biased_model = BiasedModelBellman(observation_dim=2 if _include_cart_velocity else 1, learning_rate=0.1, iterate_train=15, discount_factor=0.995)
_include_cart_velocity = True
_observation_noise_std = 0.1
_time_compression = 6
_planning_horizon = 6
n_policy_samples=700,
policy_iterations=2,
n_policy_candidates=70,
action_window=2
# > training time ~5min